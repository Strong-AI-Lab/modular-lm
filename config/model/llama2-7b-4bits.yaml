model_name: "llama2-7b-4bits"
model_path: "/data/shared/llama2/llama-2-7b-chat-weights/"
max_length: 512
model_config:
  load_in_4bit: True
tokenizer_config:
  add_eos_token: true
kwargs:
  nb_modules: 2 # Must be equal to "num_embeddings" in router config
  invariant_weight: 0.3
  hidden_dropout_prob: 0.1
  mi_dim_reduction: 256
  mi_dim_reduce_method: "max"

  